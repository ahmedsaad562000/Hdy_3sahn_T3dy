{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from libs import io , cv2 , np\n",
    "\n",
    "import preprocessing as pp\n",
    "import roi as roi\n",
    "import detection as detect\n",
    "from classifier import H3T_Classifier\n",
    "from numbers_classifier import H3T_Numbers_Classifier\n",
    "import videoread as vr\n",
    "import cameraread as cr\n",
    "from skimage import filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reload(roi)\n",
    "reload(detect)\n",
    "reload(vr)\n",
    "reload(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT\n",
    "\n",
    "sign_imgs_corr = detect.get_corrleation_matrices(\"./dataset/corr_signs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_classifier = H3T_Numbers_Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digit 0 done\n",
      "digit 1 done\n",
      "digit 2 done\n",
      "digit 3 done\n",
      "digit 4 done\n",
      "digit 5 done\n",
      "digit 6 done\n",
      "digit 7 done\n",
      "digit 8 done\n",
      "digit 9 done\n",
      "10334 10334\n"
     ]
    }
   ],
   "source": [
    "numbers_classifier.prepare_training_data(\"./dataset/training_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_classifier.train(\"svm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_classifier.save_trained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_classifier.load_trained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "videos_folder = '../../dataset/videos'\n",
    "video_frames_folder = '../../dataset/video_frames'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert videos to frames\n",
    "vr.clear_folder(video_frames_folder)\n",
    "for video_path in os.listdir(videos_folder):\n",
    "    vr.extract_frames(video_path = os.path.join(videos_folder , video_path), output_folder = video_frames_folder, fps=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of logical CPUs: 12\n"
     ]
    }
   ],
   "source": [
    "# detect number of logical cpus\n",
    "import multiprocessing\n",
    "\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "print(\"Number of logical CPUs:\", num_cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_contour(contour, thresh , charCandidates):\n",
    "    boxX, boxY, boxW, boxH = cv2.boundingRect(contour)\n",
    "\n",
    "    # compute the aspect ratio, solidity, and height ratio for the component\n",
    "    aspectRatio = boxW / float(boxH)\n",
    "    solidity = cv2.contourArea(contour) / float(boxW * boxH)\n",
    "    heightRatio = boxH / float(thresh.shape[0])\n",
    "\n",
    "    #print(solidity)\n",
    "\n",
    "    # determine if the aspect ratio, solidity, and height of the contour pass\n",
    "    # the rules tests\n",
    "    keepAspectRatio = aspectRatio < 1.0\n",
    "    keepSolidity = solidity > 0.2\n",
    "    keepHeight = heightRatio > 0.3 and heightRatio < 0.95\n",
    "\n",
    "    # check to see if the component passes all the tests\n",
    "    if keepAspectRatio and keepSolidity and keepHeight:\n",
    "        charCandidates.append((boxX, boxY, boxW, boxH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "def segement_numbers(image):\n",
    "    V = cv2.cvtColor(image , cv2.COLOR_BGR2HSV)[: ,: , 2]\n",
    "    T = filters.threshold_local(V, 27, offset=10, method=\"gaussian\")\n",
    "    thresh = (V > T).astype(\"uint8\") * 255\n",
    "    thresh = cv2.bitwise_not(thresh)\n",
    "    inverted_thresh = cv2.bitwise_not(thresh)\n",
    "    \n",
    "    # perform a connected components analysis and initialize the mask to store the locations\n",
    "    # of the character candidates\n",
    "    charCandidates = []\n",
    "    cnts , _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # ensure at least one contour was found in the mask\n",
    "    contours_length = len(cnts)\n",
    "    if contours_length <3:\n",
    "        print(\"less thann threee\")\n",
    "        return None\n",
    "    \n",
    "    threads = []\n",
    "    for i in range(contours_length):\n",
    "        thread = threading.Thread(target=process_contour, args=(cnts[i],thresh,charCandidates))\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "        \n",
    "    # Wait for all threads to finish\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "        \n",
    "    imagess = []\n",
    "\n",
    "    charCandidateslen = len(charCandidates)\n",
    "    if (charCandidateslen < 2 or charCandidateslen > 3):\n",
    "        #print(\"wrong sign detected with length = \" , len(charCandidates))\n",
    "        return None\n",
    "    \n",
    "    for i in range(charCandidateslen):\n",
    "        new_image = inverted_thresh[charCandidates[i][1]:charCandidates[i][1]+charCandidates[i][3] , charCandidates[i][0]:charCandidates[i][0]+charCandidates[i][2]]\n",
    "        new_image = cv2.resize(new_image, (16, 32))\n",
    "        prediction = numbers_classifier.predict(new_image)\n",
    "        imagess.append((charCandidates[i][0] , prediction[0].astype(int)))\n",
    "    \n",
    "    #sort by the x coordinate\n",
    "    imagess.sort(key=lambda x: -x[0])\n",
    "    \n",
    "    result = np.sum([imagess[i][1]*(10**i) for i in range(len(imagess))])\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "no sign detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yahya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\fromnumeric.py:86: FutureWarning: The behavior of DataFrame.sum with axis=None is deprecated, in a future version this will reduce over both axes and return a scalar. To retain the old behavior, pass axis=0 (or do not pass axis)\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "image = io.imread(\"./dataset/Screenshot 2023-12-24 211859.png\")\n",
    "\n",
    "resized_img = cv2.resize(image, (1280, 720))\n",
    "\n",
    "# pp.show_images([resized_img], [\"resized_img Image\"])\n",
    "\n",
    "cropped_img = cv2.hconcat([resized_img[:, :(resized_img.shape[1] // 3)]  , resized_img[:, 2 * (resized_img.shape[1] // 3):]])\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray_image = pp.gray_image(resized_img)\n",
    "# pp.show_images([gray_image], [\"Gray Image\"])\n",
    "\n",
    "equalized_image = pp.HistogramEqualization(gray_image)\n",
    "\n",
    "# Apply edge detection\n",
    "edge_image = pp.LoGEdgeDetection(equalized_image)\n",
    "\n",
    "# Extract ROIs\n",
    "rois = roi.extract_roi(edge_image , resized_img)\n",
    "\n",
    "#pp.show_images(rois)\n",
    "\n",
    "## detect sign\n",
    "if (len(rois)  == 0):\n",
    "    print(\"no rois\")\n",
    "else:\n",
    "    detected_image_index = detect.detect_sign(rois, sign_imgs_corr)\n",
    "    print(detected_image_index) \n",
    "    if detected_image_index != -1:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # new_image = pp.gray_image(rois[detected_image_index])\n",
    "\n",
    "        # # #perform opening\n",
    "        # kernel = np.ones((2,2), np.uint8)\n",
    "        # new_image = cv2.erode(new_image, kernel, iterations=2)\n",
    "        # new_image = cv2.dilate(new_image, kernel, iterations=1)\n",
    "        \n",
    "        # cropped_img = new_image[ 30:100 , 25:61 ]\n",
    "        # resized_img = cv2.resize(cropped_img, (16, 32))\n",
    "\n",
    "        # threshold = filters.threshold_otsu(resized_img)\n",
    "        # thresholded_image = np.zeros(resized_img.shape)\n",
    "        # thresholded_image[resized_img  > threshold] = 1\n",
    "        # blurred_threshold_image = filters.gaussian(thresholded_image , sigma=0.7)\n",
    "\n",
    "        # # show everything\n",
    "        # pp.show_images([new_image , thresholded_image , blurred_threshold_image])\n",
    "\n",
    "        \n",
    "\n",
    "        result = segement_numbers(rois[detected_image_index])\n",
    "        if (result != None):\n",
    "            print(f'result = {result}')\n",
    "        else: \n",
    "            print(\"no sign detected\")\n",
    "\n",
    "    else:\n",
    "        print(\"no sign detected\")\n",
    "\n",
    "# wait for 'n' key else \n",
    "#if(cv2.waitKey(1) & 0xFF == ord('n')): pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract ROIs\n",
    "rois = roi.extract_roi(edge_image , resized_img)\n",
    "\n",
    "# print(rois[0].shape)\n",
    "#show rois\n",
    "\n",
    "# new_images = []\n",
    "# for i in range(len(rois)):\n",
    "#     #  rois[i] = pp.gray_image(rois[i])\n",
    "#      new_images.append(pp.HistogramEqualization(rois[i]))\n",
    "\n",
    "pp.show_images(rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(rois)  == 0):\n",
    "    print(\"no rois\")\n",
    "else:\n",
    "    detected_image_index = detect.detect_sign(rois, sign_imgs_corr)\n",
    "    print(detected_image_index) \n",
    "    if detected_image_index != -1:\n",
    "        \n",
    "        # feature_vector , transformed_hog = hog(rois[detected_image_index] , visualize = True , channel_axis=2  , pixels_per_cell=(16, 16) , transform_sqrt=True)\n",
    "        # pp.show_images([rois[detected_image_index], transformed_hog])\n",
    "\n",
    "        # red_channel = colored_image[:, :, 0]\n",
    "        # green_channel = colored_image[:, :, 1]\n",
    "        # blue_channel = colored_image[:, :, 2]\n",
    "\n",
    "        # new_image = red_channel.copy()\n",
    "\n",
    "        # for i in range(new_image.shape[0]):\n",
    "        #     for j in range(new_image.shape[1]):\n",
    "        #         if (red_channel[i][j]  < 200 and green_channel[i][j] < 200 and blue_channel[i][j] < 200):\n",
    "        #             new_image[i][j] = 255\n",
    "        #         else:\n",
    "        #             new_image[i][j] = 0\n",
    "\n",
    "        new_image = pp.gray_image(rois[detected_image_index])\n",
    "\n",
    "\n",
    "        # #perform opening\n",
    "        kernel = np.ones((2,2), np.uint8)\n",
    "        new_image = cv2.erode(new_image, kernel, iterations=2)\n",
    "        new_image = cv2.dilate(new_image, kernel, iterations=1)\n",
    "        \n",
    "        cropped_img = new_image[ 30:100 , 25:61 ]\n",
    "        resized_img = cv2.resize(cropped_img, (16, 32))\n",
    "\n",
    "        threshold = filters.threshold_otsu(resized_img)\n",
    "        thresholded_image = np.zeros(resized_img.shape)\n",
    "        thresholded_image[resized_img  > threshold] = 1\n",
    "        blurred_threshold_image = filters.gaussian(thresholded_image , sigma=0.7)\n",
    "\n",
    "        # show everything\n",
    "        pp.show_images([new_image , thresholded_image , blurred_threshold_image])\n",
    "                \n",
    "                \n",
    "\n",
    "        print(f'prediction is {numbers_classifier.predict(blurred_threshold_image)}')\n",
    "    else:\n",
    "        print(\"no sign detected\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ip_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
